{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VarianceComponentModels.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`VarianceComponentModels.jl`](https://github.com/OpenMendel/VarianceComponentModels.jl/) is a package that resides in [OpenMendel](https://github.com/OpenMendel) ecosystem. It implements computation routines for fitting and testing variance component model of form \n",
    "\n",
    "$$\\text{vec}(Y) \\sim \\text{Normal}(XB, \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m)$$\n",
    "\n",
    "where $\\otimes$ is the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Features \n",
    "* Maximum likelihood estimation (MLE) and restricted maximum likelihood estimation (REML) of mean parameters B and variance component parameters Σ\n",
    "* Allow constrains in the mean parameters B\n",
    "* Choice of optimization algorithms: [Fisher scoring](https://books.google.com/books?id=QYqeYTftPNwC&lpg=PP1&pg=PA142#v=onepage&q&f=false) and [minorization-maximization algorithm](http://hua-zhou.github.io/media/pdf/ZhouHuZhouLange19VCMM.pdf)\n",
    "* [Heritability Analysis](https://openmendel.github.io/VarianceComponentModels.jl/latest/man/heritability/#Heritability-Analysis-1) in genetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "This package requires Julia v0.7.0 or later, which can be obtained from https://julialang.org/downloads/ or by building Julia from the sources in the https://github.com/JuliaLang/julia repository.\n",
    "\n",
    "The package has not yet been registered and must be installed using the repository location. Start julia and use the ] key to switch to the package manager REPL\n",
    "\n",
    "```julia\n",
    "(v1.3) pkg> add https://github.com/OpenMendel/VarianceComponentModels.jl.git#Julia-0.7\n",
    "```\n",
    "\n",
    "Use the backspace key to return to the Julia REPL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "* [MLE and REML](#MLE-and-REML) \n",
    "* [Heritability Analysis](#Heritability-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE and REML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.3.1\n",
      "Commit 2d5741174c (2019-12-30 21:36 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin18.6.0)\n",
      "  CPU: Intel(R) Core(TM) i5-6267U CPU @ 2.90GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration, we generate a random data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data from a d-variate response variane component model\n",
    "using Random, LinearAlgebra\n",
    "Random.seed!(123)\n",
    "n = 1000   # no. observations\n",
    "d = 2      # dimension of responses\n",
    "m = 2      # no. variance components\n",
    "p = 2      # no. covariates\n",
    "# n-by-p design matrix\n",
    "X = randn(n, p)\n",
    "# p-by-d mean component regression coefficient\n",
    "B = ones(p, d)  \n",
    "# a tuple of m covariance matrices\n",
    "V = ntuple(x -> zeros(n, n), m) \n",
    "for i = 1:m-1\n",
    "  Vi = randn(n, 50)\n",
    "  copyto!(V[i], Vi * Vi')\n",
    "end\n",
    "copyto!(V[m], Matrix(I, n, n)) # last covarianec matrix is idendity\n",
    "# a tuple of m d-by-d variance component parameters\n",
    "Σ = ntuple(x -> zeros(d, d), m) \n",
    "for i in 1:m\n",
    "  Σi = randn(d, d)\n",
    "  copyto!(Σ[i], Σi' * Σi)\n",
    "end\n",
    "# form overall nd-by-nd covariance matrix Ω\n",
    "Ω = zeros(n * d, n * d)\n",
    "for i = 1:m\n",
    "  Ω += kron(Σ[i], V[i])\n",
    "end\n",
    "Ωchol = cholesky(Ω)\n",
    "# n-by-d responses\n",
    "Y = X * B + reshape(Ωchol.L * randn(n*d), n, d);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood estimation (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the MLE of parameters $(B,\\Sigma_1,\\ldots,\\Sigma_m)$, we take 3 steps: \n",
    "\n",
    "**Step 1 (Construct data)**. Construct an instance of `VarianceComponentVariate`, which consists of fields \n",
    "\n",
    "* `Y`: $n$-by-$d$ responses\n",
    "* `X`: $n$-by-$p$ covariate matrix \n",
    "* `V=(V[1],...,V[m])`: a tuple of $n$-by-$n$ covariance matrices. The last covariance matrix must be positive definite and usually is the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:Y, :X, :V)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using VarianceComponentModels\n",
    "vcdata = VarianceComponentVariate(Y, X, V)\n",
    "fieldnames(typeof(vcdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of covariates $X$, we can simply initialize by `vcdata = VarianceComponentVariate(Y, V)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 (Construct a model)**. Construct an instance of `VarianceComponentModel`, which consists of fields\n",
    "\n",
    "* `B`: $n$-by-$p$ mean regression coefficients\n",
    "* `Σ=(Σ[1],...,Σ[m])`: variane component parameters respectively.\n",
    "\n",
    "When constructed from a VarianceComponentVariate instance, the mean parameters $B$ are initialized to be zero and the tuple of variance component parameters $\\Sigma$ to be `(eye(d),...,eye(d))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:B, :Σ, :A, :sense, :b, :lb, :ub)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel = VarianceComponentModel(vcdata)\n",
    "fieldnames(typeof(vcmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([0.0 0.0; 0.0 0.0], ([1.0 0.0; 0.0 1.0], [1.0 0.0; 0.0 1.0]), Array{Float64}(undef,0,4), Char[], Float64[], -Inf, Inf)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining fields `A`, `sense`, `b`, `lb`, `ub` specify (optional) constraints on the mean parameters `B`:\n",
    "\n",
    "$A * \\text{vec}(B) =(\\text{or } \\ge \\text{or } \\le) b$\n",
    "\n",
    "$lb \\le \\text{vec}(B) \\le ub$\n",
    "\n",
    "`A` is an constraint matrix with $pd$ columns, `sense` is a vector of charaters taking values `'<'`, `'='` or `'>'`, and `lb` and `ub` are the lower and upper bounds for `vec(B)`. By default, `A`, `sense`, `b` are empty, `lb` is `-Inf`, and `ub` is `Inf`. If any constraits are non-trivial, final estimates of `B` are enforced to satisfy them.\n",
    "\n",
    "When a better initial guess is available, we can initialize by calling `vcmodel=VarianceComponentModel(B0, Σ0)` directly.\n",
    "\n",
    "**Step 3 (Fit model)**. Call optmization routine `fit_mle!`. The keyword `algo` dictates the optimization algorithm: `:MM` (minorization-maximization algorithm) or `:FS` (Fisher scoring algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     MM Algorithm\n",
      "  Iter      Objective  \n",
      "--------  -------------\n",
      "       0  -6.253551e+03\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "       1  -3.881454e+03\n",
      "       2  -3.853179e+03\n",
      "       3  -3.846525e+03\n",
      "       4  -3.844906e+03\n",
      "       5  -3.844506e+03\n",
      "       6  -3.844406e+03\n",
      "       7  -3.844381e+03\n",
      "       8  -3.844375e+03\n",
      "       9  -3.844374e+03\n",
      "      10  -3.844373e+03\n",
      "\n",
      "  5.285482 seconds (11.44 M allocations: 570.981 MiB, 3.06% gc time)\n"
     ]
    }
   ],
   "source": [
    "vcmodel_mle = deepcopy(vcmodel)\n",
    "@time logl, vcmodel_mle, Σse, Σcov, Bse, Bcov = fit_mle!(vcmodel_mle, vcdata; algo = :MM);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `fit_mle!` contains\n",
    "\n",
    "* final log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3844.3731814180883"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:B, :Σ, :A, :sense, :b, :lb, :ub)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(vcmodel_mle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([1.0919960341406953 1.0472703873788904; 0.9553455716716395 1.016315638674718], ([0.3806371846890906 -0.30546523211690463; -0.30546523211690463 4.519380324112873], [1.8400909904775102 0.26556859919650166; 0.26556859919650166 2.172752980034015]), Array{Float64}(undef,0,4), Char[], Float64[], -Inf, Inf)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* standard errors of the estimated varianec component parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.07651361924362647 0.2630470127784574; 0.2630470127784576 0.9043321868733178], [0.08442916131150752 0.09174407350754034; 0.09174407350754071 0.09969274380846048])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Σse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* covariance matrix of the variance component parameters estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 Array{Float64,2}:\n",
       "  0.00585433  -0.00467019  -0.00467019  …  -1.07903e-6   -1.557e-7   \n",
       " -0.00467019   0.0691937    0.00372555     -1.557e-7     -1.27444e-6 \n",
       " -0.00467019   0.00372555   0.0691937      -8.83212e-6   -1.27444e-6 \n",
       "  0.00372555  -0.055198    -0.055198       -1.27444e-6   -1.04316e-5 \n",
       " -7.4779e-6   -1.07903e-6  -1.07903e-6      0.00102878    0.000148477\n",
       " -1.07903e-6  -8.83212e-6  -1.557e-7    …   0.000148477   0.00121477 \n",
       " -1.07903e-6  -1.557e-7    -8.83212e-6      0.00841698    0.00121477 \n",
       " -1.557e-7    -1.27444e-6  -1.27444e-6      0.00121477    0.00993864 "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Σcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* standard errors of the estimated mean parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.0425562  0.0483834\n",
       " 0.0430596  0.0492809"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* covariance matrix of the mean parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       "  0.00181103   -1.96485e-5    0.000243441  -4.38252e-6 \n",
       " -1.96485e-5    0.00185413   -4.38252e-6    0.000246407\n",
       "  0.000243441  -4.38252e-6    0.00234096   -5.73331e-6 \n",
       " -4.38252e-6    0.000246407  -5.73331e-6    0.00242861 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted maximum likelihood estimation (REML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[REML (restricted maximum likelihood estimation)](https://en.wikipedia.org/wiki/Restricted_maximum_likelihood) is a popular alternative to the MLE. To find the REML of a variane component model, we replace the above step 3 by\n",
    "\n",
    "**Step 3**. Call optmization routine `fit_reml!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     MM Algorithm\n",
      "  Iter      Objective  \n",
      "--------  -------------\n",
      "       0  -4.215053e+03\n",
      "       1  -3.925799e+03\n",
      "       2  -3.865114e+03\n",
      "       3  -3.851105e+03\n",
      "       4  -3.847732e+03\n",
      "       5  -3.846903e+03\n",
      "       6  -3.846698e+03\n",
      "       7  -3.846647e+03\n",
      "       8  -3.846634e+03\n",
      "       9  -3.846631e+03\n",
      "      10  -3.846630e+03\n",
      "\n",
      "  0.574157 seconds (179.03 k allocations: 71.507 MiB, 13.59% gc time)\n"
     ]
    }
   ],
   "source": [
    "vcmodel_reml = deepcopy(vcmodel)\n",
    "@time logl, vcmodel_reml, Σse, Σcov, Bse, Bcov = fit_reml!(vcmodel_reml, vcdata; algo = :MM);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of fit_reml! contains\n",
    "\n",
    "* the final log-likelihood at REML estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3844.3777179025046"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* REML estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:B, :Σ, :A, :sense, :b, :lb, :ub)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(vcmodel_reml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([1.0919959427065358 1.0472704732594296; 0.9553454519764125 1.0163157746706337], ([0.38059386475358836 -0.30548508022759785; -0.30548508022759785 4.51994275993852], [1.8428522689608946 0.26196264194000846; 0.26196264194000846 2.1784163819904427]), Array{Float64}(undef,0,4), Char[], Float64[], -Inf, Inf)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel_reml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* standard errors of the estimated variance component parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.07650553461473508 0.26304964665017927; 0.2630496466501792 0.904445863017746], [0.08455585744252603 0.09193246406052916; 0.09193246406052925 0.09995259851207343])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Σse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* covariance matrix of the variance component parameters estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 Array{Float64,2}:\n",
       "  0.0058531   -0.00467005  -0.00467005  …  -1.06597e-6   -1.51499e-7 \n",
       " -0.00467005   0.0691951    0.00372613     -1.51499e-7   -1.26041e-6 \n",
       " -0.00467005   0.00372613   0.0691951      -8.86843e-6   -1.26041e-6 \n",
       "  0.00372613  -0.0552092   -0.0552092      -1.26041e-6   -1.0486e-5  \n",
       " -7.50035e-6  -1.06597e-6  -1.06597e-6      0.00101633    0.000144472\n",
       " -1.06597e-6  -8.86843e-6  -1.51499e-7  …   0.000144472   0.0012014  \n",
       " -1.06597e-6  -1.51499e-7  -8.86843e-6      0.00845158    0.0012014  \n",
       " -1.51499e-7  -1.26041e-6  -1.26041e-6      0.0012014     0.00999052 "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Σcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* standard errors of the estimated mean parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.0425881  0.0484485\n",
       " 0.0430919  0.0493475"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* covariance matrix of the mean parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       "  0.00181375   -1.96783e-5    0.000239868  -4.34611e-6 \n",
       " -1.96783e-5    0.00185691   -4.34611e-6    0.000242745\n",
       "  0.000239868  -4.34611e-6    0.00234726   -5.73082e-6 \n",
       " -4.34611e-6    0.000242745  -5.73082e-6    0.00243518 "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the MLE or REML of variance component models is a non-trivial nonlinear optimization problem. The main complications are the non-convexity of objective function and the positive semi-definiteness constraint of variane component parameters $\\Sigma_1,\\ldots,\\Sigma_m$. In specific applications, users should try different algorithms with different starting points in order to find a better solution. Here are some tips for efficient computation.\n",
    "In general the optimization algorithm needs to invert the $nd$ by $nd$ overall covariance matrix $\\Omega = \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m$ in each iteration. Inverting a matrix is an expensive operation with $O(n^3 d^3)$ floating operations. When there are only two varianec components ($m=2$), this tedious task can be avoided by taking one (generalized) eigendecomposion of $(V_1, V_2)$ and rotating data $(Y, X)$ by the eigen-vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:Yrot, :Xrot, :eigval, :eigvec, :logdetV2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcdatarot = TwoVarCompVariateRotate(vcdata)\n",
    "fieldnames(typeof(vcdatarot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two optimization algorithms are implemented: [Fisher scoring](https://books.google.com/books?id=QYqeYTftPNwC&lpg=PP1&pg=PA142#v=onepage&q&f=false) (`mle_fs!`) and the [minorization-maximization (MM) algorithm](http://hua-zhou.github.io/media/pdf/ZhouHuZhouLange19VCMM.pdf) (`mle_mm!`). Both take the rotated data as input. These two functions give finer control of the optimization algorithms. Generally speaking, MM algorithm is more stable while Fisher scoring (if it converges) yields more accurate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     MM Algorithm\n",
      "  Iter      Objective  \n",
      "--------  -------------\n",
      "       0  -6.253551e+03\n",
      "       1  -3.881454e+03\n",
      "       2  -3.853179e+03\n",
      "       3  -3.846525e+03\n",
      "       4  -3.844906e+03\n",
      "       5  -3.844506e+03\n",
      "       6  -3.844406e+03\n",
      "       7  -3.844381e+03\n",
      "       8  -3.844375e+03\n",
      "       9  -3.844374e+03\n",
      "      10  -3.844373e+03\n",
      "\n",
      "  0.060365 seconds (19.34 k allocations: 1.274 MiB)\n"
     ]
    }
   ],
   "source": [
    "vcmodel_mm = deepcopy(vcmodel)\n",
    "@time mle_mm!(vcmodel_mm, vcdatarot; maxiter=10000, funtol=1e-8, verbose = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.092     1.04727\n",
       " 0.955346  1.01632"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MM estimates\n",
    "vcmodel_mm.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.3806371846890906 -0.30546523211690463; -0.30546523211690463 4.519380324112873], [1.8400909904775102 0.26556859919650166; 0.26556859919650166 2.172752980034015])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MM estimates\n",
    "vcmodel_mm.Σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisher scoring (`mle_fs!`) uses either [Ipopt.jl](https://github.com/JuliaOpt/Ipopt.jl) (keyword `solver=:Ipopt`) or [KNITRO.jl](https://github.com/JuliaOpt/KNITRO.jl) (keyword `solver=:Knitro`) as the backend solver. Ipopt is open source and installation of [Ipopt.jl](https://github.com/JuliaOpt/Ipopt.jl) package alone is sufficient. Knitro is a commercial software and users need to follow instructions at [KNITRO.jl](https://github.com/JuliaOpt/KNITRO.jl) for proper functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.10, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       21\n",
      "\n",
      "Total number of variables............................:        6\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  4.2109423e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n",
      "   5  3.8445586e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  10  3.8443870e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  15  3.8443742e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  20  3.8443733e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  25  3.8443732e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  30  3.8443732e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  35  3.8443732e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  40  3.8443732e+03 0.00e+00 9.19e-05 -11.0 5.55e-06    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  45  3.8443732e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  50  3.8443732e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "  55  3.8443732e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "  60  3.8443732e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "\n",
      "Number of Iterations....: 63\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   3.4496886481728779e+02    3.8443731733053728e+03\n",
      "Dual infeasibility......:   2.2693631701157965e-07    2.5290047251948971e-06\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   2.2693631701157965e-07    2.5290047251948971e-06\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 64\n",
      "Number of objective gradient evaluations             = 64\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 63\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      1.364\n",
      "Total CPU secs in NLP function evaluations           =      0.243\n",
      "\n",
      "EXIT: Solved To Acceptable Level.\n",
      "  2.362761 seconds (3.66 M allocations: 180.337 MiB, 10.86% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Fisher scoring using Ipopt\n",
    "vcmodel_ipopt = deepcopy(vcmodel)\n",
    "@time mle_fs!(vcmodel_ipopt, vcdatarot; solver=:Ipopt, maxiter=1000, verbose=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.092     1.04727\n",
       " 0.955346  1.01632"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ipopt estimates\n",
    "vcmodel_ipopt.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.3805517356051958 -0.3055935197839397; -0.3055935197839397 4.521059353384276], [1.8400802765380622 0.2653850252233819; 0.2653850252233819 2.172870198791716])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ipopt estimates\n",
    "vcmodel_ipopt.Σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: KnitroSolver not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: KnitroSolver not defined",
      "",
      "Stacktrace:",
      " [1] #mle_fs!#27(::Int64, ::Symbol, ::Symbol, ::Bool, ::typeof(mle_fs!), ::VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}, ::TwoVarCompVariateRotate{Float64,Array{Float64,2},Array{Float64,2}}) at /Users/juhyun-kim/.julia/packages/VarianceComponentModels/6qDHu/src/two_variance_component.jl:909",
      " [2] (::VarianceComponentModels.var\"#kw##mle_fs!\")(::NamedTuple{(:solver, :maxiter, :verbose),Tuple{Symbol,Int64,Bool}}, ::typeof(mle_fs!), ::VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}, ::TwoVarCompVariateRotate{Float64,Array{Float64,2},Array{Float64,2}}) at ./none:0",
      " [3] top-level scope at util.jl:155",
      " [4] top-level scope at In[37]:3"
     ]
    }
   ],
   "source": [
    "# Fisher scoring using Knitro\n",
    "vcmodel_knitro = deepcopy(vcmodel)\n",
    "@time mle_fs!(vcmodel_knitro, vcdatarot; solver=:Knitro, maxiter=1000, verbose=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few strategies for successful optimization.\n",
    "\n",
    "* For $d>1$ (multivariate response), initialize $B, \\Sigma$ from univariate estimates.\n",
    "* Use REML estimate as starting point for MLE.\n",
    "* When there are only $m=2$ variance components, pre-compute `TwoVarCompVariateRotate` and use it for optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained estimation of B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many applications invoke constraints on the mean parameters B. For demonstration, we enforce `B[1,1]=B[1,2]` and all entries of B are within [0, 2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([0.0 0.0; 0.0 0.0], ([1.0 0.0; 0.0 1.0], [1.0 0.0; 0.0 1.0]), [1.0 0.0 -1.0 0.0], '=', 0.0, 0.0, 2.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up constraints on B\n",
    "vcmodel_constr = deepcopy(vcmodel)\n",
    "vcmodel_constr.A = [1.0 0.0 -1.0 0.0]\n",
    "vcmodel_constr.sense = '='\n",
    "vcmodel_constr.b = 0.0\n",
    "vcmodel_constr.lb = 0.0\n",
    "vcmodel_constr.ub = 2.0\n",
    "vcmodel_constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     MM Algorithm\n",
      "  Iter      Objective  \n",
      "--------  -------------\n",
      "       0  -6.253551e+03\n",
      "       1  -3.881820e+03\n",
      "       2  -3.853477e+03\n",
      "       3  -3.846807e+03\n",
      "       4  -3.845184e+03\n",
      "       5  -3.844783e+03\n",
      "       6  -3.844683e+03\n",
      "       7  -3.844658e+03\n",
      "       8  -3.844652e+03\n",
      "       9  -3.844650e+03\n",
      "      10  -3.844650e+03\n",
      "\n",
      "  0.191956 seconds (157.81 k allocations: 8.210 MiB)\n"
     ]
    }
   ],
   "source": [
    "# MM algorithm for constrained estimation of B\n",
    "@time mle_mm!(vcmodel_constr, vcdatarot; maxiter=10000, funtol=1e-8, verbose = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:B, :Σ, :A, :sense, :b, :lb, :ub)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(vcmodel_constr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.07177   1.07177\n",
       " 0.955683  1.01591"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel_constr.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.38062446987069126 -0.30549750554026933; -0.30549750554026933 4.519477725102305], [1.8405108260586278 0.2650648215816033; 0.2650648215816033 2.1733573050720496])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel_constr.Σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try Fisher scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.10, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       21\n",
      "\n",
      "Total number of variables............................:        6\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  4.2114270e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n",
      "   5  3.8448353e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  10  3.8446636e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  15  3.8446509e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  20  3.8446499e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  25  3.8446498e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  30  3.8446498e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  35  3.8446498e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  40  3.8446498e+03 0.00e+00 9.19e-05 -11.0 5.56e-06    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  45  3.8446498e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  50  3.8446498e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "  55  3.8446498e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00h  1 MaxSA\n",
      "  60  3.8446498e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "\n",
      "Number of Iterations....: 63\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   3.4484507551949679e+02    3.8446498170293380e+03\n",
      "Dual infeasibility......:   2.2694405212011240e-07    2.5301808562731130e-06\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   2.2694405212011240e-07    2.5301808562731130e-06\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 64\n",
      "Number of objective gradient evaluations             = 64\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 63\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.029\n",
      "Total CPU secs in NLP function evaluations           =      0.651\n",
      "\n",
      "EXIT: Solved To Acceptable Level.\n",
      "  0.958871 seconds (95.91 k allocations: 7.977 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Fisher scoring using Ipopt for constrained estimation of B\n",
    "vcmodel_constr = deepcopy(vcmodel)\n",
    "vcmodel_constr.A = [1.0 0.0 -1.0 0.0]\n",
    "vcmodel_constr.sense = '='\n",
    "vcmodel_constr.b = 0.0\n",
    "vcmodel_constr.lb = 0.0\n",
    "vcmodel_constr.ub = 2.0\n",
    "vcmodel_constr\n",
    "@time mle_fs!(vcmodel_constr, vcdatarot; solver=:Ipopt, maxiter=1000, verbose=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.07177   1.07177\n",
       " 0.955683  1.01591"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel_constr.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.38053902231656933 -0.30562579795954326; -0.30562579795954326 4.521156860574265], [1.840500109410487 0.2648809570723453; 0.2648809570723453 2.173475215913481])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcmodel_constr.Σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heritability Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
