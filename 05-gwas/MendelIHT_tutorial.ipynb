{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative hard thresholding Tutorial\n",
    "\n",
    "This notebook showcase a few examples of the software [MendelIHT.jl](https://github.com/OpenMendel/MendelIHT.jl). \n",
    "\n",
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.2.0\n",
      "Commit c6da87ff4b (2019-08-20 00:03 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin18.6.0)\n",
      "  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "# machine information for reproducibility\n",
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load necessary packages, install them if you don't have it\n",
    "using MendelIHT\n",
    "using SnpArrays\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using GLM\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install OpenMendel related packages, execute the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/SnpArrays.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/SnpArrays.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/SnpArrays.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelSearch.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelSearch.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/MendelSearch.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelBase.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelBase.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/MendelBase.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelIHT.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/OpenMendel/MendelIHT.jl`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "]add https://github.com/OpenMendel/MendelIHT.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is IHT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative hard thresholding (IHT) is a sparse approximation method that performs variable selection and parameter estimation for high dimensional datasets. IHT returns a sparse model with prespecified $k \\in \\mathbb{Z}_+$ (or fewer) non-zero entries. In [MendelIHT.j](), the objective function is:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{maximize } & \\quad L(\\beta)\\\\\n",
    "\\text{subject to } & \\quad ||\\beta||_0 \\le k\n",
    "\\end{align}\n",
    "\n",
    "The objective is solved via:\n",
    "$$\\beta_{n+1} = P_{S_k}(\\beta_n - s_n \\nabla L(\\beta_n)),$$\n",
    "where:\n",
    "+ $\\nabla L(\\beta)$ is the score (gradient) vector of loglikelihood\n",
    "+ $J(\\beta)$ is the expected information (hessian) matrix\n",
    "+ $s = \\frac{||\\nabla L(\\beta)||_2^2}{\\nabla L(\\beta)^tJ(\\beta)\\nabla L(\\beta)}$ is the step size\n",
    "+ $P_{S_k}(v)$ projects vector $v$ to sparsity set $S_k$ by setting all but the top $k$ entries to 0. \n",
    "\n",
    "See [our paper](https://www.biorxiv.org/content/10.1101/697755v2) for more details and computational tricks to do each of these efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supported GLM models and Link functions\n",
    "\n",
    "MendelIHT borrows distribution and link functions implementationed in [GLM.jl](http://juliastats.github.io/GLM.jl/stable/) and [Distributions.jl](https://juliastats.github.io/Distributions.jl/stable/).\n",
    "\n",
    "| Distribution | Canonical Link | Status |\n",
    "|:---:|:---:|:---:|\n",
    "| Normal | IdentityLink | $\\checkmark$ |\n",
    "| Bernoulli | LogitLink |$\\checkmark$ |\n",
    "| Poisson | LogLink |  $\\checkmark$ |\n",
    "| NegativeBinomial | LogLink |  $\\checkmark$ |\n",
    "| Gamma | InverseLink | experimental |\n",
    "| InverseGaussian | InverseSquareLink | experimental |\n",
    "\n",
    "Examples of these distributions in their default value is visualized in [this post](https://github.com/JuliaStats/GLM.jl/issues/289).\n",
    "\n",
    "### Available link functions\n",
    "\n",
    "    CauchitLink\n",
    "    CloglogLink\n",
    "    IdentityLink\n",
    "    InverseLink\n",
    "    InverseSquareLink\n",
    "    LogitLink\n",
    "    LogLink\n",
    "    ProbitLink\n",
    "    SqrtLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: How to Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate example data (to be imported later)\n",
    "\n",
    "First we simulate an example PLINK trio (`.bim`, `.bed`, `.fam`) and non-genetic covariates, then we illustrate how to import them. For genotype matrix simulation, we simulate under the model:\n",
    "\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rows and columns\n",
    "n = 1000\n",
    "p = 10000\n",
    "\n",
    "#random seed\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate random `.bed` file\n",
    "x = simulate_random_snparray(n, p, \"./data/tmp.bed\")\n",
    "\n",
    "# create accompanying `.bim`, `.fam` files (randomly generated)\n",
    "make_bim_fam_files(x, ones(n), \"./data/tmp\")\n",
    "\n",
    "# simulate non-genetic covariates (in this case, we include intercept and sex)\n",
    "z = [ones(n, 1) rand(0:1, n)]\n",
    "writedlm(\"./data/tmp_nongenetic_covariates.txt\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Genotype data and Non-Genetic Covariates from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000Ã—2 Array{Float64,2}:\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " â‹®       \n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0\n",
       " 1.0  0.0\n",
       " 1.0  1.0\n",
       " 1.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = SnpArray(\"./data/tmp.bed\")\n",
    "z = readdlm(\"./data/tmp_nongenetic_covariates.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Non-Genetic Covariates.\n",
    "\n",
    "We recommend standardizing all genetic and non-genetic covarariates (including binary and categorical), except for the intercept. This ensures equal penalization for all predictors. For genotype matrix, `SnpBitMatrix` efficiently achieves this standardization. For non-genetic covariates, we use the built-in function `standardize!`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000Ã—2 Array{Float64,2}:\n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " â‹®             \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622\n",
       " 1.0  -0.952622\n",
       " 1.0   1.04868 \n",
       " 1.0  -0.952622"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SnpBitMatrix can automatically standardizes .bed file (without extra memory) and behaves like a matrix\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n",
    "\n",
    "# using view is important for correctness\n",
    "standardize!(@view(z[:, 2:end])) \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Running IHT on Quantitative Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, our model is simulated as:\n",
    "\n",
    "$$y_i \\sim \\mathbf{x}_i^T\\mathbf{\\beta} + \\epsilon_i$$\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "$$\\epsilon_i \\sim \\rm N(0, 1)$$\n",
    "$$\\beta_i \\sim \\rm N(0, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model dimensions, true model size, distribution, and link functions\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "d = Normal\n",
    "l = canonicallink(d())\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate SNP matrix, store the result in a file called tmp.bed\n",
    "x = simulate_random_snparray(n, p, \"./data/tmp.bed\")\n",
    "\n",
    "#construct the SnpBitMatrix type (needed for L0_reg() and simulate_random_response() below)\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true); \n",
    "\n",
    "# intercept is the only nongenetic covariate\n",
    "z = ones(n, 1) \n",
    "\n",
    "# simulate response y, true model b, and the correct non-0 positions of b\n",
    "y, true_b, correct_position = simulate_random_response(x, xbm, k, d, l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run `q`-fold cross validation to determine best model size\n",
    "\n",
    "To run `cv_iht`, you must specify `path` and `q`, defined below:\n",
    "\n",
    "+ **`path`**: all the model sizes you wish to test.\n",
    "+ **`q`**: number of disjoint partitions of your data. \n",
    "\n",
    "By default, we partition the training/testing data randomly, but you can change this by inputing the `fold` vector as optional argument. In this example we tested $k = 5, 6, ..., 15$ across 3 fold cross validation. This is equivalent to running IHT across 30 different models, and hence, is ideal for parallel computing (which you specify by `parallel=true`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crossvalidation Results:\n",
      "\tk\tMSE\n",
      "\t5\t372.3937119552455\n",
      "\t6\t353.5092453930539\n",
      "\t7\t336.18623388015544\n",
      "\t8\t342.3436390290969\n",
      "\t9\t355.6163808836806\n",
      "\t10\t355.92769511323513\n",
      "\t11\t367.05441286229495\n",
      "\t12\t374.1270669623582\n",
      "\t13\t368.0104754338581\n",
      "\t14\t367.4956307418699\n",
      "\t15\t385.3773400406478\n",
      " 15.336045 seconds (15.66 M allocations: 847.403 MiB, 2.54% gc time)\n"
     ]
    }
   ],
   "source": [
    "path = collect(5:15)\n",
    "q = 3\n",
    "\n",
    "@time mses = cv_iht(d(), l, x, z, y, 1, path, q, parallel=false); # don't run parallel on binder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run IHT on full model for best estimated k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 7 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.26702284812927246\n",
       "Final loglikelihood:    -1409.8966823858416\n",
       "Iterations:             5\n",
       "\n",
       "Selected genetic predictors:\n",
       "7Ã—2 DataFrame\n",
       "â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚\n",
       "â”‚     â”‚ \u001b[90mInt64\u001b[39m    â”‚ \u001b[90mFloat64\u001b[39m     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 1   â”‚ 173      â”‚ 0.240557    â”‚\n",
       "â”‚ 2   â”‚ 4779     â”‚ -1.10532    â”‚\n",
       "â”‚ 3   â”‚ 7159     â”‚ 1.19246     â”‚\n",
       "â”‚ 4   â”‚ 7357     â”‚ 1.63064     â”‚\n",
       "â”‚ 5   â”‚ 8276     â”‚ 0.222044    â”‚\n",
       "â”‚ 6   â”‚ 8529     â”‚ -0.4526     â”‚\n",
       "â”‚ 7   â”‚ 8942     â”‚ -0.890789   â”‚\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0Ã—2 DataFrame\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = path[argmin(mses)]\n",
    "result = L0_reg(x, xbm, z, y, 1, best_k, d(), l) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check final model against simulation\n",
    "\n",
    "Since all our data and model was simulated, we can see how well `cv_iht` combined with `L0_reg` estimated the true model. For this example, we find that IHT found every simulated predictor, with 0 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>true_Î²</th><th>estimated_Î²</th></tr><tr><th></th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows Ã— 2 columns</p><tr><th>1</th><td>0.290051</td><td>0.240557</td></tr><tr><th>2</th><td>0.113896</td><td>0.0</td></tr><tr><th>3</th><td>-1.09083</td><td>-1.10532</td></tr><tr><th>4</th><td>0.0326341</td><td>0.0</td></tr><tr><th>5</th><td>1.25615</td><td>1.19246</td></tr><tr><th>6</th><td>1.5655</td><td>1.63064</td></tr><tr><th>7</th><td>-0.0616128</td><td>0.0</td></tr><tr><th>8</th><td>0.240515</td><td>0.222044</td></tr><tr><th>9</th><td>-0.420895</td><td>-0.4526</td></tr><tr><th>10</th><td>-0.893621</td><td>-0.890789</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& true\\_Î² & estimated\\_Î²\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.290051 & 0.240557 \\\\\n",
       "\t2 & 0.113896 & 0.0 \\\\\n",
       "\t3 & -1.09083 & -1.10532 \\\\\n",
       "\t4 & 0.0326341 & 0.0 \\\\\n",
       "\t5 & 1.25615 & 1.19246 \\\\\n",
       "\t6 & 1.5655 & 1.63064 \\\\\n",
       "\t7 & -0.0616128 & 0.0 \\\\\n",
       "\t8 & 0.240515 & 0.222044 \\\\\n",
       "\t9 & -0.420895 & -0.4526 \\\\\n",
       "\t10 & -0.893621 & -0.890789 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10Ã—2 DataFrame\n",
       "â”‚ Row â”‚ true_Î²     â”‚ estimated_Î² â”‚\n",
       "â”‚     â”‚ \u001b[90mFloat64\u001b[39m    â”‚ \u001b[90mFloat64\u001b[39m     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 1   â”‚ 0.290051   â”‚ 0.240557    â”‚\n",
       "â”‚ 2   â”‚ 0.113896   â”‚ 0.0         â”‚\n",
       "â”‚ 3   â”‚ -1.09083   â”‚ -1.10532    â”‚\n",
       "â”‚ 4   â”‚ 0.0326341  â”‚ 0.0         â”‚\n",
       "â”‚ 5   â”‚ 1.25615    â”‚ 1.19246     â”‚\n",
       "â”‚ 6   â”‚ 1.5655     â”‚ 1.63064     â”‚\n",
       "â”‚ 7   â”‚ -0.0616128 â”‚ 0.0         â”‚\n",
       "â”‚ 8   â”‚ 0.240515   â”‚ 0.222044    â”‚\n",
       "â”‚ 9   â”‚ -0.420895  â”‚ -0.4526     â”‚\n",
       "â”‚ 10  â”‚ -0.893621  â”‚ -0.890789   â”‚"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model = DataFrame(\n",
    "    true_Î²      = true_b[correct_position], \n",
    "    estimated_Î² = result.beta[correct_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** IHT found 7/10 true predictors, with superb parameter estimates. The remaining 3 predictors cannot be identified by IHT because they have very small effect sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Negative Binomial regression with group information \n",
    "\n",
    "Now we show how to include group information to perform **doubly sparse** projections. This results in a model with at most $j$ groups where each group contains at most $k$ SNPs. This is useful for:\n",
    "\n",
    "+ Data with extensive LD blocks (i.e. correlated covariates)\n",
    "+ Prior knowledge on genes/pathways\n",
    "\n",
    "## Simulation: IHT on extensive LD blocks\n",
    "In this example, we simulated:\n",
    "+ 10,000 SNPs, each belonging to 1 of 500 disjoint groups. Each group contains 20 SNPs\n",
    "+ $j = 5$ distinct groups are each assigned $1,2,...,5$ causal SNPs with effect sizes randomly chosen from $\\{âˆ’0.2,0.2\\}$. \n",
    "+ Within group correlation: $\\rho = 0.95$\n",
    "\n",
    "**We assume perfect group information**. That is, the selected groups containing 1âˆ¼5 causative SNPs are assigned maximum within-group sparsity $\\lambda_g = 1,2,...,5$. The remaining groups are assigned $\\lambda_g = 1$ (i.e. only 1 active predictor are allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define problem size\n",
    "d = NegativeBinomial\n",
    "l = LogLink()\n",
    "n = 1000\n",
    "p = 10000\n",
    "block_size = 20                  #simulation parameter\n",
    "num_blocks = Int(p / block_size) #simulation parameter\n",
    "\n",
    "# set seed\n",
    "Random.seed!(2020)\n",
    "\n",
    "# assign group membership\n",
    "membership = collect(1:num_blocks)\n",
    "g = zeros(Int64, p + 1)\n",
    "for i in 1:length(membership)\n",
    "    for j in 1:block_size\n",
    "        cur_row = block_size * (i - 1) + j\n",
    "        g[block_size*(i - 1) + j] = membership[i]\n",
    "    end\n",
    "end\n",
    "g[end] = membership[end]\n",
    "\n",
    "#simulate correlated snparray\n",
    "x = simulate_correlated_snparray(n, p, \"./data/tmp2.bed\", prob=0.95)\n",
    "z = ones(n, 1) # the intercept\n",
    "x_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)\n",
    "\n",
    "#simulate true model, where 5 groups each with 1~5 snps contribute\n",
    "true_b = zeros(p)\n",
    "true_groups = randperm(num_blocks)[1:5]\n",
    "sort!(true_groups)\n",
    "within_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], \n",
    "                randperm(block_size)[1:3], randperm(block_size)[1:4], \n",
    "                randperm(block_size)[1:5]]\n",
    "correct_position = zeros(Int64, 15)\n",
    "for i in 1:5\n",
    "    cur_group = block_size * (true_groups[i] - 1)\n",
    "    cur_group_snps = cur_group .+ within_group[i]\n",
    "    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)\n",
    "    correct_position[start:last] .= cur_group_snps\n",
    "end\n",
    "for i in 1:15\n",
    "    true_b[correct_position[i]] = rand(-1:2:1) * 0.2\n",
    "end\n",
    "sort!(correct_position)\n",
    "\n",
    "# simulate phenotype\n",
    "r = 10 #nuisance parameter\n",
    "Î¼ = GLM.linkinv.(l, x_float * true_b)\n",
    "clamp!(Î¼, -20, 20)\n",
    "prob = 1 ./ (1 .+ Î¼ ./ r)\n",
    "y = [rand(d(r, i)) for i in prob] #number of failures before r success occurs\n",
    "y = Float64.(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT without group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.27208900451660156\n",
       "Final loglikelihood:    -1506.9803043373497\n",
       "Iterations:             56\n",
       "\n",
       "Selected genetic predictors:\n",
       "15Ã—2 DataFrame\n",
       "â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚\n",
       "â”‚     â”‚ \u001b[90mInt64\u001b[39m    â”‚ \u001b[90mFloat64\u001b[39m     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 1   â”‚ 4476     â”‚ -0.12189    â”‚\n",
       "â”‚ 2   â”‚ 4477     â”‚ -0.12189    â”‚\n",
       "â”‚ 3   â”‚ 4509     â”‚ -0.173135   â”‚\n",
       "â”‚ 4   â”‚ 4516     â”‚ -0.159284   â”‚\n",
       "â”‚ 5   â”‚ 5382     â”‚ -0.173063   â”‚\n",
       "â”‚ 6   â”‚ 5384     â”‚ -0.0968715  â”‚\n",
       "â”‚ 7   â”‚ 5385     â”‚ -0.0968715  â”‚\n",
       "â”‚ 8   â”‚ 5386     â”‚ -0.0968715  â”‚\n",
       "â”‚ 9   â”‚ 7442     â”‚ 0.194584    â”‚\n",
       "â”‚ 10  â”‚ 7443     â”‚ 0.194584    â”‚\n",
       "â”‚ 11  â”‚ 7446     â”‚ 0.337898    â”‚\n",
       "â”‚ 12  â”‚ 8531     â”‚ 0.195654    â”‚\n",
       "â”‚ 13  â”‚ 8532     â”‚ 0.195654    â”‚\n",
       "â”‚ 14  â”‚ 8535     â”‚ 0.161302    â”‚\n",
       "â”‚ 15  â”‚ 8536     â”‚ 0.151602    â”‚\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0Ã—2 DataFrame\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 15\n",
    "ungrouped_IHT = L0_reg(x_float, z, y, 1, k, d(), l) # 1 means 1 active group = entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT with group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "IHT estimated 15 nonzero SNP predictors and 0 non-genetic predictors.\n",
       "\n",
       "Compute time (sec):     0.3959381580352783\n",
       "Final loglikelihood:    -1490.9710283926524\n",
       "Iterations:             48\n",
       "\n",
       "Selected genetic predictors:\n",
       "15Ã—2 DataFrame\n",
       "â”‚ Row â”‚ Position â”‚ Estimated_Î² â”‚\n",
       "â”‚     â”‚ \u001b[90mInt64\u001b[39m    â”‚ \u001b[90mFloat64\u001b[39m     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 1   â”‚ 4475     â”‚ -0.210736   â”‚\n",
       "â”‚ 2   â”‚ 4509     â”‚ -0.173963   â”‚\n",
       "â”‚ 3   â”‚ 4517     â”‚ -0.155094   â”‚\n",
       "â”‚ 4   â”‚ 5381     â”‚ -0.16722    â”‚\n",
       "â”‚ 5   â”‚ 5382     â”‚ -0.16722    â”‚\n",
       "â”‚ 6   â”‚ 5397     â”‚ 0.267128    â”‚\n",
       "â”‚ 7   â”‚ 7442     â”‚ 0.176729    â”‚\n",
       "â”‚ 8   â”‚ 7443     â”‚ 0.176729    â”‚\n",
       "â”‚ 9   â”‚ 7446     â”‚ 0.288789    â”‚\n",
       "â”‚ 10  â”‚ 7450     â”‚ 0.139096    â”‚\n",
       "â”‚ 11  â”‚ 8526     â”‚ -0.196314   â”‚\n",
       "â”‚ 12  â”‚ 8531     â”‚ 0.48662     â”‚\n",
       "â”‚ 13  â”‚ 8534     â”‚ 0.0427654   â”‚\n",
       "â”‚ 14  â”‚ 8536     â”‚ 0.233248    â”‚\n",
       "â”‚ 15  â”‚ 8540     â”‚ 0.0302228   â”‚\n",
       "\n",
       "Selected nongenetic predictors:\n",
       "0Ã—2 DataFrame\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify maximum number of active groups\n",
    "J = 5 \n",
    "\n",
    "# specify within-group sparsity for each group\n",
    "max_group_snps = ones(Int, num_blocks) \n",
    "max_group_snps[true_groups] .= collect(1:5)\n",
    "\n",
    "# run grouped IHT\n",
    "grouped_IHT = L0_reg(x_float, z, y, J, max_group_snps, d(), l, verbose=false, group=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check variable selection against true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>correct_positions</th><th>ungrouped_IHT_positions</th><th>grouped_IHT_positions</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>15 rows Ã— 3 columns</p><tr><th>1</th><td>4477</td><td>4476</td><td>4475</td></tr><tr><th>2</th><td>4510</td><td>4477</td><td>4509</td></tr><tr><th>3</th><td>4517</td><td>4509</td><td>4517</td></tr><tr><th>4</th><td>5381</td><td>4516</td><td>5381</td></tr><tr><th>5</th><td>5385</td><td>5382</td><td>5382</td></tr><tr><th>6</th><td>5397</td><td>5384</td><td>5397</td></tr><tr><th>7</th><td>7443</td><td>5385</td><td>7442</td></tr><tr><th>8</th><td>7444</td><td>5386</td><td>7443</td></tr><tr><th>9</th><td>7446</td><td>7442</td><td>7446</td></tr><tr><th>10</th><td>7452</td><td>7443</td><td>7450</td></tr><tr><th>11</th><td>8526</td><td>7446</td><td>8526</td></tr><tr><th>12</th><td>8531</td><td>8531</td><td>8531</td></tr><tr><th>13</th><td>8532</td><td>8532</td><td>8534</td></tr><tr><th>14</th><td>8534</td><td>8535</td><td>8536</td></tr><tr><th>15</th><td>8536</td><td>8536</td><td>8540</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& correct\\_positions & ungrouped\\_IHT\\_positions & grouped\\_IHT\\_positions\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 4477 & 4476 & 4475 \\\\\n",
       "\t2 & 4510 & 4477 & 4509 \\\\\n",
       "\t3 & 4517 & 4509 & 4517 \\\\\n",
       "\t4 & 5381 & 4516 & 5381 \\\\\n",
       "\t5 & 5385 & 5382 & 5382 \\\\\n",
       "\t6 & 5397 & 5384 & 5397 \\\\\n",
       "\t7 & 7443 & 5385 & 7442 \\\\\n",
       "\t8 & 7444 & 5386 & 7443 \\\\\n",
       "\t9 & 7446 & 7442 & 7446 \\\\\n",
       "\t10 & 7452 & 7443 & 7450 \\\\\n",
       "\t11 & 8526 & 7446 & 8526 \\\\\n",
       "\t12 & 8531 & 8531 & 8531 \\\\\n",
       "\t13 & 8532 & 8532 & 8534 \\\\\n",
       "\t14 & 8534 & 8535 & 8536 \\\\\n",
       "\t15 & 8536 & 8536 & 8540 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "15Ã—3 DataFrame\n",
       "â”‚ Row â”‚ correct_positions â”‚ ungrouped_IHT_positions â”‚ grouped_IHT_positions â”‚\n",
       "â”‚     â”‚ \u001b[90mInt64\u001b[39m             â”‚ \u001b[90mInt64\u001b[39m                   â”‚ \u001b[90mInt64\u001b[39m                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 1   â”‚ 4477              â”‚ 4476                    â”‚ 4475                  â”‚\n",
       "â”‚ 2   â”‚ 4510              â”‚ 4477                    â”‚ 4509                  â”‚\n",
       "â”‚ 3   â”‚ 4517              â”‚ 4509                    â”‚ 4517                  â”‚\n",
       "â”‚ 4   â”‚ 5381              â”‚ 4516                    â”‚ 5381                  â”‚\n",
       "â”‚ 5   â”‚ 5385              â”‚ 5382                    â”‚ 5382                  â”‚\n",
       "â”‚ 6   â”‚ 5397              â”‚ 5384                    â”‚ 5397                  â”‚\n",
       "â”‚ 7   â”‚ 7443              â”‚ 5385                    â”‚ 7442                  â”‚\n",
       "â”‚ 8   â”‚ 7444              â”‚ 5386                    â”‚ 7443                  â”‚\n",
       "â”‚ 9   â”‚ 7446              â”‚ 7442                    â”‚ 7446                  â”‚\n",
       "â”‚ 10  â”‚ 7452              â”‚ 7443                    â”‚ 7450                  â”‚\n",
       "â”‚ 11  â”‚ 8526              â”‚ 7446                    â”‚ 8526                  â”‚\n",
       "â”‚ 12  â”‚ 8531              â”‚ 8531                    â”‚ 8531                  â”‚\n",
       "â”‚ 13  â”‚ 8532              â”‚ 8532                    â”‚ 8534                  â”‚\n",
       "â”‚ 14  â”‚ 8534              â”‚ 8535                    â”‚ 8536                  â”‚\n",
       "â”‚ 15  â”‚ 8536              â”‚ 8536                    â”‚ 8540                  â”‚"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model = DataFrame(\n",
    "    correct_positions = correct_position,\n",
    "    ungrouped_IHT_positions = findall(!iszero, ungrouped_IHT.beta),\n",
    "    grouped_IHT_positions = findall(!iszero, grouped_IHT.beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check estimated parameters against true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>position</th><th>correct_Î²</th><th>ungrouped_IHT_Î²</th><th>grouped_IHT_Î²</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>15 rows Ã— 4 columns</p><tr><th>1</th><td>4477</td><td>-0.2</td><td>-0.12189</td><td>0.0</td></tr><tr><th>2</th><td>4510</td><td>-0.2</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>4517</td><td>-0.2</td><td>0.0</td><td>-0.155094</td></tr><tr><th>4</th><td>5381</td><td>-0.2</td><td>0.0</td><td>-0.16722</td></tr><tr><th>5</th><td>5385</td><td>-0.2</td><td>-0.0968715</td><td>0.0</td></tr><tr><th>6</th><td>5397</td><td>0.2</td><td>0.0</td><td>0.267128</td></tr><tr><th>7</th><td>7443</td><td>0.2</td><td>0.194584</td><td>0.176729</td></tr><tr><th>8</th><td>7444</td><td>0.2</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>7446</td><td>0.2</td><td>0.337898</td><td>0.288789</td></tr><tr><th>10</th><td>7452</td><td>0.2</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>8526</td><td>-0.2</td><td>0.0</td><td>-0.196314</td></tr><tr><th>12</th><td>8531</td><td>0.2</td><td>0.195654</td><td>0.48662</td></tr><tr><th>13</th><td>8532</td><td>0.2</td><td>0.195654</td><td>0.0</td></tr><tr><th>14</th><td>8534</td><td>0.2</td><td>0.0</td><td>0.0427654</td></tr><tr><th>15</th><td>8536</td><td>0.2</td><td>0.151602</td><td>0.233248</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& position & correct\\_Î² & ungrouped\\_IHT\\_Î² & grouped\\_IHT\\_Î²\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 4477 & -0.2 & -0.12189 & 0.0 \\\\\n",
       "\t2 & 4510 & -0.2 & 0.0 & 0.0 \\\\\n",
       "\t3 & 4517 & -0.2 & 0.0 & -0.155094 \\\\\n",
       "\t4 & 5381 & -0.2 & 0.0 & -0.16722 \\\\\n",
       "\t5 & 5385 & -0.2 & -0.0968715 & 0.0 \\\\\n",
       "\t6 & 5397 & 0.2 & 0.0 & 0.267128 \\\\\n",
       "\t7 & 7443 & 0.2 & 0.194584 & 0.176729 \\\\\n",
       "\t8 & 7444 & 0.2 & 0.0 & 0.0 \\\\\n",
       "\t9 & 7446 & 0.2 & 0.337898 & 0.288789 \\\\\n",
       "\t10 & 7452 & 0.2 & 0.0 & 0.0 \\\\\n",
       "\t11 & 8526 & -0.2 & 0.0 & -0.196314 \\\\\n",
       "\t12 & 8531 & 0.2 & 0.195654 & 0.48662 \\\\\n",
       "\t13 & 8532 & 0.2 & 0.195654 & 0.0 \\\\\n",
       "\t14 & 8534 & 0.2 & 0.0 & 0.0427654 \\\\\n",
       "\t15 & 8536 & 0.2 & 0.151602 & 0.233248 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "15Ã—4 DataFrame\n",
       "â”‚ Row â”‚ position â”‚ correct_Î² â”‚ ungrouped_IHT_Î² â”‚ grouped_IHT_Î² â”‚\n",
       "â”‚     â”‚ \u001b[90mInt64\u001b[39m    â”‚ \u001b[90mFloat64\u001b[39m   â”‚ \u001b[90mFloat64\u001b[39m         â”‚ \u001b[90mFloat64\u001b[39m       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 1   â”‚ 4477     â”‚ -0.2      â”‚ -0.12189        â”‚ 0.0           â”‚\n",
       "â”‚ 2   â”‚ 4510     â”‚ -0.2      â”‚ 0.0             â”‚ 0.0           â”‚\n",
       "â”‚ 3   â”‚ 4517     â”‚ -0.2      â”‚ 0.0             â”‚ -0.155094     â”‚\n",
       "â”‚ 4   â”‚ 5381     â”‚ -0.2      â”‚ 0.0             â”‚ -0.16722      â”‚\n",
       "â”‚ 5   â”‚ 5385     â”‚ -0.2      â”‚ -0.0968715      â”‚ 0.0           â”‚\n",
       "â”‚ 6   â”‚ 5397     â”‚ 0.2       â”‚ 0.0             â”‚ 0.267128      â”‚\n",
       "â”‚ 7   â”‚ 7443     â”‚ 0.2       â”‚ 0.194584        â”‚ 0.176729      â”‚\n",
       "â”‚ 8   â”‚ 7444     â”‚ 0.2       â”‚ 0.0             â”‚ 0.0           â”‚\n",
       "â”‚ 9   â”‚ 7446     â”‚ 0.2       â”‚ 0.337898        â”‚ 0.288789      â”‚\n",
       "â”‚ 10  â”‚ 7452     â”‚ 0.2       â”‚ 0.0             â”‚ 0.0           â”‚\n",
       "â”‚ 11  â”‚ 8526     â”‚ -0.2      â”‚ 0.0             â”‚ -0.196314     â”‚\n",
       "â”‚ 12  â”‚ 8531     â”‚ 0.2       â”‚ 0.195654        â”‚ 0.48662       â”‚\n",
       "â”‚ 13  â”‚ 8532     â”‚ 0.2       â”‚ 0.195654        â”‚ 0.0           â”‚\n",
       "â”‚ 14  â”‚ 8534     â”‚ 0.2       â”‚ 0.0             â”‚ 0.0427654     â”‚\n",
       "â”‚ 15  â”‚ 8536     â”‚ 0.2       â”‚ 0.151602        â”‚ 0.233248      â”‚"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check result\n",
    "correct_position = findall(!iszero, true_b)\n",
    "compare_model = DataFrame(\n",
    "    position = correct_position,\n",
    "    correct_Î² = true_b[correct_position],\n",
    "    ungrouped_IHT_Î² = ungrouped_IHT.beta[correct_position], \n",
    "    grouped_IHT_Î² = grouped_IHT.beta[correct_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion:** by asking for \"top entries\" in each group, we (somewhat) disentangle the correlation structure in our data and achieved better model selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples:\n",
    "\n",
    "Please visit our [documentation](https://openmendel.github.io/MendelIHT.jl/latest/).\n",
    "\n",
    "## Other functionalities\n",
    "\n",
    "+ Analyze large GWAS datasets intuitively.\n",
    "+ Built-in support for [PLINK binary files](https://www.cog-genomics.org/plink/1.9/input#bed) via [SnpArrays.jl](https://github.com/OpenMendel/SnpArrays.jl) and [VCF files](https://en.wikipedia.org/wiki/Variant_Call_Format) via [VCFTools.jl](https://github.com/OpenMendel/VCFTools.jl).\n",
    "+ Out-of-the-box parallel computing routines for `q-fold` cross-validation.\n",
    "+ Fits a variety of generalized linear models with any choice of link function.\n",
    "+ Computation directly on raw genotype files.\n",
    "+ Efficient handlings for non-genetic covariates.\n",
    "+ Optional acceleration (debias) step to dramatically improve speed.\n",
    "+ Ability to explicitly incorporate weights for predictors.\n",
    "+ Ability to enforce within and between group sparsity. \n",
    "+ Naive genotype imputation. \n",
    "+ Estimates nuisance parameter for negative binomial regression using Newton or MM algorithm. \n",
    "+ Excellent flexibility to handle different data structures and complements well with other Julia packages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
